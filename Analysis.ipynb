{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file in\n",
    "df = pd.read_parquet('B19001_no_geometry.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the KD Tree\n",
    "centroids = df[['CentroidX', 'CentroidY', 'CentroidZ']].to_numpy()\n",
    "c_tree = KDTree(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at https://www.bls.gov/cex/tables.htm \n",
    "https://www.bls.gov/cex/2019/combined/income.xlsx\n",
    "\n",
    "Household ops, housekeeping supplies, laundry supplies, postage, textiles, furniture, floor coverings, small appliances, misc equipment, clothing, av equipment, pets/toys/hobbies/playground equipment, personal care, reading\n",
    "\n",
    "| <15          | 15-30        | 30-40        | 40-50        | 50-70        | 70-100       | 100-150      | 150-200      | >200         |\n",
    "|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|\n",
    "|  $ 4,370.00  |  $ 5,767.00  |  $ 6,681.00  |  $ 7,959.00  |  $ 8,712.00  |  $10,655.00  |  $13,396.00  |  $17,638.00  |  $26,174.00  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the data into expected spending per income group.\n",
    "levels = [\n",
    "    4370,\n",
    "    4370,\n",
    "    5767,\n",
    "    5767,\n",
    "    5767,\n",
    "    6681,\n",
    "    6681,\n",
    "    7959,\n",
    "    7959,\n",
    "    8712,\n",
    "    8712,\n",
    "    10655,\n",
    "    13396,\n",
    "    13396,\n",
    "    17638,\n",
    "    26174\n",
    "]\n",
    "level_columns = df.columns[13:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the expected amount available to spend per entire block group for all block groups in the US\n",
    "spending_potential = np.einsum('ij,j->i', df[level_columns], levels)\n",
    "spending_potential[np.where(np.isnan(spending_potential))] = 0\n",
    "spending_potential[spending_potential == np.inf] = 0\n",
    "grounded_potential = spending_potential.copy()\n",
    "grounded_potential[np.abs(grounded_potential - grounded_potential.mean()) > 4 * grounded_potential.std()] = grounded_potential.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the top num_search block groups with highest spending potential, looking min_search_dist away for the subsequent best block groups.\n",
    "num_search = 40\n",
    "min_search_dist = 50\n",
    "\n",
    "available_indexes = np.arange(len(grounded_potential))\n",
    "top_locations = np.zeros(num_search, dtype=np.int)\n",
    "\n",
    "for idx in range(num_search):\n",
    "    best_index = available_indexes[grounded_potential[available_indexes].argmax()]\n",
    "    top_locations[idx] = best_index\n",
    "    \n",
    "    off_limits = c_tree.query_ball_point(centroids[best_index], min_search_dist)\n",
    "    available_indexes = available_indexes[~np.isin(available_indexes, off_limits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all info for the best locations.\n",
    "best_locs = df.iloc[top_locations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result.\n",
    "best_locs.to_csv('SearchResult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the names of the top selected sites\n",
    "best_locs['NAME'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the top 20.\n",
    "\n",
    "neighboring_areas = [np.array(x) for x in c_tree.query_ball_point(centroids[top_locations], 20)]\n",
    "region_arr = np.zeros((len(neighboring_areas), max([len(x) for x in neighboring_areas])), dtype=np.int)\n",
    "\n",
    "for i in range(len(neighboring_areas)):\n",
    "    region_arr[i, :len(neighboring_areas[i])] = neighboring_areas[i]\n",
    "    \n",
    "np.savetxt('TargetRegions.csv', region_arr, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the top 10.\n",
    "\n",
    "neighboring_areas = [np.array(x) for x in c_tree.query_ball_point(centroids[top_locations], 10)]\n",
    "region_arr = np.zeros((len(neighboring_areas), max([len(x) for x in neighboring_areas])), dtype=np.int)\n",
    "\n",
    "for i in range(len(neighboring_areas)):\n",
    "    region_arr[i, :len(neighboring_areas[i])] = neighboring_areas[i]\n",
    "    \n",
    "np.savetxt('TwoTargetRegions.csv', region_arr[:2], delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geo Python",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
